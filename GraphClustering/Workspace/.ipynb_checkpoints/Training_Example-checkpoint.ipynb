{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/nikol/Documents/GitHub/GFlowNetsA/GraphClustering\")\n",
    "\n",
    "import torch\n",
    "from Network import GraphNet\n",
    "from IRM_generative_torch import IRM_graph, clusterIndex\n",
    "from IRM_post import Cmatrix_to_array, torch_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes is the only parameter with no default, so the graph must be created before the network. Here we create a synthetic graph generated from the stochastic processes we assume formed the graph in the IRM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, int, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14716\\372902630.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mA_random\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjacency_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcluster_random\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster_idxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA_random\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tensors used as indices must be long, int, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "N =  20 \n",
    "adjacency_matrix, clusters = IRM_graph(3, 0.5, 0.5, N = 20)\n",
    "cluster_idxs = clusterIndex(clusters)\n",
    "# Adjacency_matrix describes the graph. \n",
    "# Cluster_idxs is the ground truth and was used to form the graph.\n",
    "# idxs = torch.random.permutation(torch.arange(N))\n",
    "idxs = torch.randperm(N)\n",
    "\n",
    "A_random = adjacency_matrix[idxs][:, idxs] \n",
    "cluster_random = cluster_idxs[A_random]\n",
    "\n",
    "\n",
    "# adjacency_matrix = torch.ones((5, 5))\n",
    "# adjacency_matrix[0, 1], adjacency_matrix[1, 0] = 0, 0\n",
    "# adjacency_matrix[0, 3], adjacency_matrix[3, 0] = 0, 0\n",
    "# adjacency_matrix[0, 4], adjacency_matrix[4, 0] = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network is created as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GraphNet(n_nodes=adjacency_matrix.size()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the network is a vector of length 2 * (n_nodes ^ 2) + n_nodes. The first n_nodes^2 is the adjacency matrix, the next is the clustering matrix specifying which nodes are in the same cluster and the final n_nodes indicate which node was most recently placed into a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toell\\AppData\\Local\\Temp\\ipykernel_9980\\2140478734.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b = torch.concat((torch.tensor(adjacency_matrix).flatten(), torch.tensor(clustering_mat).flatten(), last_node_placed))\n"
     ]
    }
   ],
   "source": [
    "clustering_list = torch.tensor([1, 1, 2, 3, 0])\n",
    "clustering_mat = net.get_clustering_matrix(clustering_list, 4)\n",
    "last_node_placed = torch.zeros(5)\n",
    "last_node_placed[3] = 1\n",
    "b = torch.concat((torch.tensor(adjacency_matrix).flatten(), torch.tensor(clustering_mat).flatten(), last_node_placed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train, one must first sample a number of clusterings using sample_forward, which will sample using the current network along with added randomness. The amount of randomness is set using the parameter 'gamma' when instantiating the network. Default is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:22<00:00,  3.22s/it]\n",
      "100%|██████████| 100/100 [00:03<00:00, 25.99it/s]\n",
      "100%|██████████| 10/10 [00:30<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "X = net.sample_forward(adjacency_matrix=adjacency_matrix)\n",
    "net.train(X, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished, sampling again will produce different results. If you only want complete clusterings, set the net property 'termination_chance' to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\GFlowNetsA\\GraphClustering\\Network\\Network.py:234: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  clustering_list[node_chosen] = torch.tensor(cluster_index_chosen + 1, dtype=torch.float32)\n",
      "100%|██████████| 100/100 [00:06<00:00, 14.65it/s]\n"
     ]
    }
   ],
   "source": [
    "net.termination_chance = 0\n",
    "X1 = net.sample_forward(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These new samples have the same length as the input to the network, so use indexing to get the clustering matrix or use the method of the GraphNet class called get_matrices_from_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_clusterings = []\n",
    "av_post_pretrain = 0\n",
    "for x in X:\n",
    "    pretrain_clusterings.append(net.get_matrices_from_state(x))\n",
    "    av_post_pretrain += torch_posterior(A_random, Cmatrix_to_array(clusterings[-1]), a=torch.ones(1), b=torch.ones(1), alpha = 1, log=True) \n",
    "\n",
    "posttrain_clusterings = []\n",
    "av_post_posttrain = 0\n",
    "for x in X1:\n",
    "    pretrain_clusterings.append(net.get_matrices_from_state(x))\n",
    "    av_post_posttrain += torch_posterior(A_random, Cmatrix_to_array(clusterings[-1]), a=torch.ones(1), b=torch.ones(1), alpha = 1, log=True) \n",
    "\n",
    "print(av_post_pretrain, \"should be lower than\", av_post_posttrain, \"given we sample enough. \\n\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
